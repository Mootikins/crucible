//! Vault File Parsing Tests - Phase 1A TDD Implementation
//!
//! This file contains comprehensive tests for vault file parsing functionality.
//! Tests are written FIRST and will initially FAIL before implementation.
//!
//! TDD Process:
//! 1. Write failing tests (this file)
//! 2. Verify tests fail (run cargo test)
//! 3. Implement minimal code to make tests pass
//! 4. Refactor while keeping tests passing

use chrono::Datelike;
use serde_json::Value;

/// Test vault path for integration testing
const TEST_VAULT_PATH: &str = "/home/moot/Documents/crucible-testing";

#[tokio::test]
async fn test_vault_scanner_finds_markdown_files() {
    // This test should FAIL initially before implementation
    // Tests that vault scanner can discover markdown files in directory

    let scanner = crucible_tools::vault_scanner::VaultScanner::new(TEST_VAULT_PATH);
    let markdown_files = scanner.scan_markdown_files().await.unwrap();

    // Verify we found markdown files in the test vault
    assert!(
        !markdown_files.is_empty(),
        "Should find markdown files in test vault"
    );

    // Verify all entries are markdown files
    for file_path in &markdown_files {
        assert!(
            file_path.extension().unwrap_or_default() == "md",
            "All files should have .md extension, found: {:?}",
            file_path
        );
    }

    // Verify we found expected files from the test vault
    let file_paths: Vec<String> = markdown_files
        .iter()
        .map(|p| p.to_string_lossy().to_string())
        .collect();

    // Should find known files in the test vault
    assert!(
        file_paths.iter().any(|p| p.contains("PRIME.md")),
        "Should find PRIME.md in test vault"
    );
    assert!(
        file_paths.iter().any(|p| p.contains("Rune MCP")),
        "Should find Rune MCP files in test vault"
    );
}

#[tokio::test]
async fn test_frontmatter_parsing_extracts_metadata() {
    // This test should FAIL initially before implementation
    // Tests that markdown parser can extract YAML frontmatter

    let parser = crucible_tools::vault_parser::VaultParser::new();

    // Test with a real file from the test vault
    let test_file_path = format!("{}/PRIME.md", TEST_VAULT_PATH);
    let vault_file = parser.parse_file(&test_file_path).await.unwrap();

    // Verify frontmatter was extracted
    assert!(
        vault_file.metadata.frontmatter.contains_key("type"),
        "Should extract 'type' field from frontmatter"
    );
    assert!(
        vault_file.metadata.frontmatter.contains_key("tags"),
        "Should extract 'tags' field from frontmatter"
    );

    // Verify specific values from PRIME.md
    let frontmatter_type = vault_file.metadata.frontmatter.get("type").unwrap();
    assert_eq!(
        frontmatter_type,
        &Value::String("meta".to_string()),
        "Type should be 'meta' for PRIME.md"
    );

    // Verify tags array
    let tags = vault_file.metadata.frontmatter.get("tags").unwrap();
    if let Value::Array(tag_array) = tags {
        assert!(
            tag_array.contains(&Value::String("vault-config".to_string())),
            "Should contain 'vault-config' tag"
        );
        assert!(
            tag_array.contains(&Value::String("instructions".to_string())),
            "Should contain 'instructions' tag"
        );
    } else {
        panic!("Tags should be an array, got: {:?}", tags);
    }
}

#[tokio::test]
async fn test_file_change_detection_via_hashing() {
    // This test should FAIL initially before implementation
    // Tests that file change detection works via SHA256 hashing

    let change_detector = crucible_tools::vault_change_detection::ChangeDetector::new();

    // Test file path
    let test_file_path = format!("{}/PRIME.md", TEST_VAULT_PATH);

    // Get initial hash
    let initial_hash = change_detector
        .calculate_file_hash(&test_file_path)
        .await
        .unwrap();
    assert!(!initial_hash.is_empty(), "Hash should not be empty");
    assert_eq!(
        initial_hash.len(),
        64,
        "SHA256 hash should be 64 characters"
    );

    // Verify hash is consistent
    let second_hash = change_detector
        .calculate_file_hash(&test_file_path)
        .await
        .unwrap();
    assert_eq!(
        initial_hash, second_hash,
        "Hash should be consistent for unchanged file"
    );

    // Test with different file (should have different hash)
    let different_file_path = format!("{}/Projects/Rune MCP/Rune MCP - MoC.md", TEST_VAULT_PATH);
    let different_hash = change_detector
        .calculate_file_hash(&different_file_path)
        .await
        .unwrap();
    assert_ne!(
        initial_hash, different_hash,
        "Different files should have different hashes"
    );
}

#[tokio::test]
async fn test_vault_parsing_integration_with_real_files() {
    // This test should FAIL initially before implementation
    // Tests full integration: scanning + parsing + metadata extraction

    let vault_path = TEST_VAULT_PATH;
    let scanner = crucible_tools::vault_scanner::VaultScanner::new(vault_path);
    let parser = crucible_tools::vault_parser::VaultParser::new();

    // Scan for markdown files
    let markdown_files = scanner.scan_markdown_files().await.unwrap();
    assert!(!markdown_files.is_empty(), "Should find markdown files");

    // Parse first few files, but make sure to include PRIME.md
    let mut parsed_files = Vec::new();
    let mut prime_file_found = false;

    for file_path in markdown_files.iter() {
        let absolute_path = format!("{}/{}", vault_path, file_path.to_string_lossy());
        let vault_file = parser.parse_file(&absolute_path).await.unwrap();

        // Always include PRIME.md if found
        if file_path.to_string_lossy().contains("PRIME.md") {
            prime_file_found = true;
            parsed_files.push(vault_file);
        }
        // Include other files up to 5 total
        else if parsed_files.len() < 5 {
            parsed_files.push(vault_file);
        }

        // Stop once we have PRIME.md + up to 4 other files
        if prime_file_found && parsed_files.len() >= 5 {
            break;
        }
    }

    // Verify all files have required fields
    for vault_file in &parsed_files {
        assert!(
            !vault_file.path.to_string_lossy().is_empty(),
            "File path should not be empty"
        );
        assert!(
            !vault_file.content.is_empty(),
            "Content should not be empty"
        );
        assert!(!vault_file.hash.is_empty(), "Hash should not be empty");
        assert!(
            vault_file.metadata.size > 0,
            "File size should be greater than 0"
        );

        // Verify frontmatter structure
        let frontmatter = &vault_file.metadata.frontmatter;
        if frontmatter.contains_key("type") {
            let file_type = frontmatter.get("type").unwrap();
            assert!(file_type.is_string(), "Type should be a string");
        }

        if frontmatter.contains_key("tags") {
            let tags = frontmatter.get("tags").unwrap();
            assert!(tags.is_array(), "Tags should be an array");
        }
    }

    // Test specific file properties
    let prime_file = parsed_files
        .iter()
        .find(|f| f.path.to_string_lossy().contains("PRIME.md"))
        .expect("Should find PRIME.md in parsed files");

    assert_eq!(
        prime_file.metadata.frontmatter.get("type").unwrap(),
        &Value::String("meta".to_string())
    );
    assert!(
        prime_file.content.contains("# Vault Primer"),
        "Content should contain expected markdown"
    );
}

#[tokio::test]
async fn test_error_handling_missing_file() {
    // This test should FAIL initially before implementation
    // Tests error handling for non-existent files

    let parser = crucible_tools::vault_parser::VaultParser::new();
    let nonexistent_path = format!("{}/nonexistent_file.md", TEST_VAULT_PATH);

    let result = parser.parse_file(&nonexistent_path).await;

    assert!(result.is_err(), "Should return error for missing file");

    match result.unwrap_err() {
        crucible_tools::vault_types::VaultError::FileNotFound(path) => {
            assert!(
                path.contains("nonexistent_file.md"),
                "Error should mention missing file"
            );
        }
        other => panic!("Expected FileNotFound error, got: {:?}", other),
    }
}

#[tokio::test]
async fn test_error_handling_malformed_frontmatter() {
    // This test should FAIL initially before implementation
    // Tests error handling for malformed YAML frontmatter

    // We'll need to create a temporary file with malformed frontmatter
    // For now, this is a placeholder for the test structure
    let parser = crucible_tools::vault_parser::VaultParser::new();

    // This test would require creating a temp file with bad YAML
    // Implementation to follow after basic structure is in place

    // For now, just verify the error type exists
    let _error_type =
        crucible_tools::vault_types::VaultError::FrontmatterParseError("test error".to_string());
}

#[tokio::test]
async fn test_vault_scanner_recursive_directory_traversal() {
    // This test should FAIL initially before implementation
    // Tests that scanner properly traverses subdirectories

    let vault_path = TEST_VAULT_PATH;
    let scanner = crucible_tools::vault_scanner::VaultScanner::new(vault_path);

    // Test recursive scanning (default behavior)
    let all_files = scanner.scan_markdown_files().await.unwrap();

    // Test non-recursive scanning
    let root_only_files = scanner.scan_markdown_files_non_recursive().await.unwrap();

    // Should find more files with recursive scanning
    assert!(
        all_files.len() > root_only_files.len(),
        "Recursive scanning should find more files than non-recursive"
    );

    // Verify subdirectories are included in recursive scan
    let has_subdir_files = all_files.iter().any(|p| {
        p.to_string_lossy().contains("Projects/") || p.to_string_lossy().contains("Sessions/")
    });
    assert!(
        has_subdir_files,
        "Recursive scan should include subdirectory files"
    );
}

#[tokio::test]
async fn test_vault_metadata_extraction_various_frontmatter_types() {
    // This test should FAIL initially before implementation
    // Tests parsing different frontmatter field types

    let parser = crucible_tools::vault_parser::VaultParser::new();

    // Parse files with different frontmatter structures
    let test_files = vec![
        "PRIME.md",                               // Has type, tags, created, status
        "Projects/Rune MCP/Rune MCP - MoC.md",    // Has project, tags, created, status
        "Sessions/Session Summary 2025-10-11.md", // Has type, date, topics, status
    ];

    for file_name in test_files {
        let full_path = format!("{}/{}", TEST_VAULT_PATH, file_name);
        let vault_file = parser.parse_file(&full_path).await.unwrap();

        let frontmatter = &vault_file.metadata.frontmatter;

        // Verify common fields exist and have correct types
        if frontmatter.contains_key("tags") {
            let tags = frontmatter.get("tags").unwrap();
            assert!(tags.is_array(), "Tags should be an array");
        }

        if frontmatter.contains_key("created") || frontmatter.contains_key("date") {
            let date_field = frontmatter
                .get("created")
                .or_else(|| frontmatter.get("date"))
                .unwrap();
            assert!(date_field.is_string(), "Date fields should be strings");
        }

        if frontmatter.contains_key("status") {
            let status = frontmatter.get("status").unwrap();
            assert!(status.is_string(), "Status should be a string");
        }

        // Verify content extraction worked
        assert!(
            vault_file.content.contains("#"),
            "Content should contain markdown headers"
        );
    }
}

// ===== PHASE 1B: FAILING TESTS FOR MOCK TOOL REPLACEMENT =====
// These tests should FAIL initially because mock tools return hardcoded mock data,
// not real data from the test vault at /home/moot/Documents/crucible-testing

#[tokio::test]
async fn test_search_by_properties_returns_real_vault_data_not_mock_data() {
    // This test should FAIL initially because search_by_properties returns mock data
    // instead of real data from the test vault

    use crucible_tools::vault_tools;
    use serde_json::json;

    let tool_fn = vault_tools::search_by_properties();
    let parameters = json!({
        "properties": {
            "type": "meta"
        }
    });

    let result = tool_fn(
        "search_by_properties".to_string(),
        parameters,
        Some("test_user".to_string()),
        Some("test_session".to_string()),
    )
    .await
    .unwrap();

    assert!(result.success);
    let data = result.data.unwrap();
    let matching_files = data.get("matching_files").unwrap().as_array().unwrap();

    // This should FAIL because mock implementation returns hardcoded "projects/project1.md"
    // but we expect real files from the test vault like "PRIME.md"
    assert!(
        !matching_files.is_empty(),
        "Should find files with type=meta"
    );

    // Check if any result contains real vault file (not mock data)
    let has_real_vault_file = matching_files.iter().any(|file| {
        if let Some(path) = file.get("path").and_then(|p| p.as_str()) {
            // Mock data returns "projects/project1.md" - real vault should have different paths
            path.contains("PRIME.md") || path.contains("Rune MCP") || path.contains("Sessions/")
        } else {
            false
        }
    });

    // This assertion should FAIL initially (mock data vs real data)
    assert!(
        has_real_vault_file,
        "Expected real vault files like PRIME.md, but got mock data. Found files: {:?}",
        matching_files
    );
}

#[tokio::test]
async fn test_search_by_tags_finds_real_vault_files_not_mock_data() {
    // This test should FAIL initially because search_by_tags returns mock data
    // instead of real tagged files from the test vault

    use crucible_tools::vault_tools;
    use serde_json::json;

    let tool_fn = vault_tools::search_by_tags();
    let parameters = json!({
        "tags": ["vault-config", "instructions"]
    });

    let result = tool_fn(
        "search_by_tags".to_string(),
        parameters,
        Some("test_user".to_string()),
        Some("test_session".to_string()),
    )
    .await
    .unwrap();

    assert!(result.success);
    let data = result.data.unwrap();
    let matching_files = data.get("matching_files").unwrap().as_array().unwrap();

    // Mock returns "knowledge/ai.md" but real vault should have PRIME.md with these tags
    let has_prime_file = matching_files.iter().any(|file| {
        if let Some(path) = file.get("path").and_then(|p| p.as_str()) {
            path.contains("PRIME.md")
        } else {
            false
        }
    });

    // This should FAIL initially (mock data vs real data)
    assert!(
        has_prime_file,
        "Expected PRIME.md with vault-config and instructions tags, but got mock data. Found: {:?}",
        matching_files
    );
}

#[tokio::test]
async fn test_search_by_folder_returns_real_files_from_test_vault() {
    // This test should FAIL initially because search_by_folder returns mock data
    // instead of real files from the test vault folders

    use crucible_tools::vault_tools;
    use serde_json::json;

    let tool_fn = vault_tools::search_by_folder();
    let parameters = json!({
        "path": "Projects",
        "recursive": true
    });

    let result = tool_fn(
        "search_by_folder".to_string(),
        parameters,
        Some("test_user".to_string()),
        Some("test_session".to_string()),
    )
    .await
    .unwrap();

    assert!(result.success);
    let data = result.data.unwrap();
    let files = data.get("files").unwrap().as_array().unwrap();

    // Mock returns "projects/active/project1.md" but real vault should have different structure
    let has_rune_mcp_files = files.iter().any(|file| {
        if let Some(path) = file.get("path").and_then(|p| p.as_str()) {
            path.contains("Rune MCP") || path.contains("Multi-Agent")
        } else {
            false
        }
    });

    // This should FAIL initially (mock data vs real data)
    assert!(
        has_rune_mcp_files,
        "Expected real files from Projects folder like Rune MCP, but got mock data. Found: {:?}",
        files
    );
}

#[tokio::test]
async fn test_get_kiln_stats_calculates_real_statistics_not_mock_numbers() {
    // This test should FAIL initially because get_kiln_stats returns hardcoded mock numbers
    // instead of real statistics from the test vault

    use crucible_tools::vault_tools;
    use serde_json::json;

    let tool_fn = vault_tools::get_kiln_stats();
    let parameters = json!({});

    let result = tool_fn("get_kiln_stats".to_string(), parameters, None, None)
        .await
        .unwrap();

    assert!(result.success);
    let data = result.data.unwrap();

    // Mock returns hardcoded 1250 total_notes, but real vault should have different count
    let total_notes = data.get("total_notes").unwrap().as_u64().unwrap();
    let total_size_mb = data.get("total_size_mb").unwrap().as_f64().unwrap();

    // Mock returns exactly 156.7 for size - real vault should be different
    // This should FAIL initially because we expect real calculation, not mock values
    assert_ne!(
        total_notes, 1250,
        "Expected real vault note count, not mock value of 1250. Got: {}",
        total_notes
    );
    assert_ne!(
        total_size_mb, 156.7,
        "Expected real vault size calculation, not mock value of 156.7. Got: {}",
        total_size_mb
    );

    // Real vault should have specific structure indicators
    if let Some(vault_type) = data.get("vault_type").and_then(|v| v.as_str()) {
        assert_eq!(vault_type, "obsidian", "Vault type should be obsidian");
    }

    // Real stats should not be perfect round numbers like mock data
    // This is a heuristic to detect mock vs real data
    let is_perfect_round_number = total_size_mb * 10.0 == (total_size_mb * 10.0).round();
    assert!(
        !is_perfect_round_number,
        "Real vault size should not be a perfect round number like mock data. Got: {}",
        total_size_mb
    );
}

#[tokio::test]
async fn test_list_tags_extracts_real_tags_from_vault_frontmatter() {
    // This test should FAIL initially because list_tags returns hardcoded mock tags
    // instead of extracting real tags from test vault frontmatter

    use crucible_tools::vault_tools;
    use serde_json::json;

    let tool_fn = vault_tools::list_tags();
    let parameters = json!({});

    let result = tool_fn("list_tags".to_string(), parameters, None, None)
        .await
        .unwrap();

    assert!(result.success);
    let data = result.data.unwrap();
    let tags = data.get("tags").unwrap().as_array().unwrap();

    // Mock returns hardcoded tags: ["ai", "research", "project"]
    // Real vault should have different tags like "vault-config", "instructions", "ai-guide"
    let has_vault_config_tag = tags.iter().any(|tag| {
        if let Some(name) = tag.get("name").and_then(|n| n.as_str()) {
            name == "vault-config" || name == "ai-guide" || name == "instructions"
        } else {
            false
        }
    });

    // This should now pass with real vault tags
    assert!(has_vault_config_tag,
           "Expected real vault tags like 'vault-config' from PRIME.md, but got mock tags. Found: {:?}",
           tags);

    // Check that counts are realistic (not perfect round numbers like mock data)
    let total_tags = data.get("total_tags").unwrap().as_u64().unwrap();
    assert_ne!(
        total_tags, 3,
        "Expected real tag count from vault, not mock value of 3. Got: {}",
        total_tags
    );
}

// ===== ADVANCED METADATA EXTRACTION FAILING TESTS =====
// These tests should FAIL because advanced metadata processing is not yet implemented

#[tokio::test]
async fn test_metadata_extraction_normalizes_tags_and_dates() {
    // This test should FAIL because metadata normalization is not implemented

    use crucible_tools::vault_parser::VaultParser;

    let parser = VaultParser::new();
    let test_file_path = format!("{}/PRIME.md", TEST_VAULT_PATH);
    let vault_file = parser.parse_file(&test_file_path).await.unwrap();

    // Test tag normalization (lowercase, hyphen-separated)
    let tags = vault_file.get_tags();
    assert!(!tags.is_empty(), "Should extract tags from PRIME.md");

    // Tags should be normalized (letters should be lowercase, hyphens are allowed)
    for tag in &tags {
        // Check that all alphabetic characters are lowercase (allow hyphens and numbers)
        for c in tag.chars() {
            if c.is_alphabetic() {
                assert!(
                    c.is_ascii_lowercase(),
                    "Character '{}' in tag '{}' should be lowercase",
                    c,
                    tag
                );
            }
        }
        assert!(
            !tag.contains(' '),
            "Tag '{}' should use hyphens instead of spaces",
            tag
        );
    }

    // Test date parsing - PRIME.md has created date
    if let Some(created_date) = vault_file.metadata.created {
        assert!(
            created_date.year() >= 2020,
            "Created date should be realistic"
        );
        assert!(
            created_date.year() <= 2025,
            "Created date should not be in future"
        );
    }
}

#[tokio::test]
async fn test_metadata_extraction_handles_various_frontmatter_formats() {
    // This test should FAIL because flexible frontmatter parsing is not fully implemented

    use crucible_tools::vault_parser::VaultParser;

    let parser = VaultParser::new();
    let test_files = vec![
        "PRIME.md",
        "Projects/Rune MCP/Rune MCP - MoC.md",
        "Sessions/Session Summary 2025-10-11.md",
    ];

    for file_name in test_files {
        let full_path = format!("{}/{}", TEST_VAULT_PATH, file_name);
        if std::path::Path::new(&full_path).exists() {
            let vault_file = parser.parse_file(&full_path).await.unwrap();

            // Each file should have proper frontmatter extraction
            assert!(
                !vault_file.metadata.frontmatter.is_empty(),
                "{} should have frontmatter",
                file_name
            );

            // Should extract tags properly regardless of format
            let tags = vault_file.get_tags();
            // Some files might not have tags, but parsing should not fail
            if !tags.is_empty() {
                for tag in &tags {
                    assert!(!tag.is_empty(), "Tags should not be empty strings");
                }
            }
        }
    }
}

#[tokio::test]
async fn test_metadata_extraction_calculates_content_metrics() {
    // This test should FAIL because content analysis is not implemented

    use crucible_tools::vault_parser::VaultParser;

    let parser = VaultParser::new();
    let test_file_path = format!("{}/PRIME.md", TEST_VAULT_PATH);
    let vault_file = parser.parse_file(&test_file_path).await.unwrap();

    // Content should be analyzed for basic metrics
    assert!(
        !vault_file.content.is_empty(),
        "Content should not be empty"
    );

    // Should calculate word count (this feature doesn't exist yet)
    let word_count = vault_file.content.split_whitespace().count();
    assert!(word_count > 0, "Should calculate word count from content");
    assert!(word_count > 50, "PRIME.md should have substantial content");

    // Should extract structure information (headers, etc.)
    let has_headers = vault_file
        .content
        .lines()
        .any(|line| line.trim().starts_with('#'));
    assert!(has_headers, "Should detect markdown headers in content");
}

#[tokio::test]
async fn test_metadata_extraction_handles_relationships_and_links() {
    // This test should FAIL because relationship extraction is not implemented

    use crucible_tools::vault_parser::VaultParser;

    let parser = VaultParser::new();
    let test_file_path = format!("{}/Projects/Rune MCP/Rune MCP - MoC.md", TEST_VAULT_PATH);

    if std::path::Path::new(&test_file_path).exists() {
        let vault_file = parser.parse_file(&test_file_path).await.unwrap();

        // Should detect internal links (wikilinks)
        let has_wikilinks = vault_file.content.contains("[[") && vault_file.content.contains("]]");
        // This might fail if the file doesn't have wikilinks, but parsing should work

        // Should extract document relationships (not implemented yet)
        // This is a placeholder for the test structure
        let content_lines: Vec<&str> = vault_file.content.lines().collect();
        assert!(
            !content_lines.is_empty(),
            "Should have content lines to analyze"
        );
    }
}

// ===== FILE ENCODING TESTS =====
// These tests document the CRITICAL limitation that vault parser only supports UTF-8.
// Files encoded in UTF-16 (common on Windows), Latin-1, Windows-1252, or other encodings
// will either fail with "invalid UTF-8" error or produce garbage characters.
//
// Current implementation: `crates/crucible-tools/src/vault_parser.rs:42`
//   let content = fs::read_to_string(&full_path)?;  // Only handles UTF-8!
//
// These tests serve dual purposes:
// 1. Document current limitations - Show which encodings fail
// 2. Provide test harness for future encoding support
//
// Expected test results (Current Implementation):
// - UTF-8 tests: PASS (baseline)
// - UTF-16 tests: FAIL (expected - documents limitation)
// - Legacy encoding tests: FAIL (expected - documents limitation)
// - Malformed UTF-8 tests: FAIL or produce replacement chars (expected)

mod encoding_tests {
    use super::*;
    use std::fs;
    use std::path::Path;
    use tempfile::TempDir;

    // Test helper: Create file with specific encoding
    fn create_encoded_file(
        path: &Path,
        content: &str,
        encoding: &'static encoding_rs::Encoding,
    ) -> Result<(), std::io::Error> {
        let (encoded, _, _) = encoding.encode(content);
        fs::write(path, &*encoded)
    }

    // Test helper: Create UTF-8 file with BOM
    fn create_utf8_bom_file(path: &Path, content: &str) -> Result<(), std::io::Error> {
        let mut data = vec![0xEF, 0xBB, 0xBF]; // UTF-8 BOM
        data.extend_from_slice(content.as_bytes());
        fs::write(path, data)
    }

    // Test helper: Create UTF-16 file with BOM
    fn create_utf16_bom_file(
        path: &Path,
        content: &str,
        little_endian: bool,
    ) -> Result<(), std::io::Error> {
        let encoding = if little_endian {
            encoding_rs::UTF_16LE
        } else {
            encoding_rs::UTF_16BE
        };
        let (encoded, _, _) = encoding.encode(content);
        let mut data = if little_endian {
            vec![0xFF, 0xFE] // UTF-16 LE BOM
        } else {
            vec![0xFE, 0xFF] // UTF-16 BE BOM
        };
        data.extend_from_slice(&encoded);
        fs::write(path, data)
    }

    // Test helper: Create malformed UTF-8 file
    fn create_malformed_utf8_file(path: &Path) -> Result<(), std::io::Error> {
        // Invalid UTF-8 sequence: Start of 3-byte sequence but missing continuation bytes
        let invalid_utf8 = vec![
            b'#', b' ', b'T', b'e', b's', b't', b'\n', b'\n',
            0xE0, 0x80, // Invalid: incomplete 3-byte sequence
            b'c', b'o', b'n', b't', b'e', b'n', b't',
        ];
        fs::write(path, invalid_utf8)
    }

    const UTF16_TEST_CONTENT: &str = r#"---
title: UTF-16 Test File
encoding: utf-16
---
# Test Heading

This file uses UTF-16 encoding, common on Windows systems.

Special characters: cafÃ©, naÃ¯ve, rÃ©sumÃ©
Emoji: ðŸŽ‰ ðŸš€ âœ¨
"#;

    const LEGACY_TEST_CONTENT: &str = r#"---
title: Legacy Encoding Test
encoding: latin-1
---
# Test Content

Special characters: cafÃ©, naÃ¯ve, rÃ©sumÃ©, Ã‘oÃ±o
"#;

    const MULTILINGUAL_CONTENT: &str = r#"---
title: Multilingual Test
languages: [chinese, arabic, cyrillic]
---
# Multilingual Content

Chinese: ä½ å¥½ä¸–ç•Œ (Hello World)
Arabic: Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù… (Hello World)
Cyrillic: ÐŸÑ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€ (Hello World)
Japanese: ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ (Hello World)
"#;

    // ===== PRIORITY 1: UTF-16 ENCODING TESTS (4 tests) =====

    #[tokio::test]
    async fn test_parse_utf16_le_encoded_file() {
        // Tests UTF-16 Little Endian (most common on Windows)
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("utf16le.md");

        // Create UTF-16 LE encoded file
        create_encoded_file(&file_path, UTF16_TEST_CONTENT, encoding_rs::UTF_16LE).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        // Current expected behavior: FAIL with UTF-8 error
        // Future expected behavior: SUCCESS with auto-detection
        match result {
            Ok(doc) => {
                // If this passes, encoding detection was added!
                assert!(doc.content.contains("cafÃ©"));
                println!("âœ“ UTF-16 LE encoding is now supported!");
            }
            Err(e) => {
                // Expected: "invalid utf-8" or similar
                eprintln!("âš ï¸  UTF-16 LE not yet supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }

    #[tokio::test]
    async fn test_parse_utf16_be_encoded_file() {
        // Tests UTF-16 Big Endian
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("utf16be.md");

        // Create UTF-16 BE encoded file
        create_encoded_file(&file_path, UTF16_TEST_CONTENT, encoding_rs::UTF_16BE).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        match result {
            Ok(doc) => {
                assert!(doc.content.contains("cafÃ©"));
                println!("âœ“ UTF-16 BE encoding is now supported!");
            }
            Err(e) => {
                eprintln!("âš ï¸  UTF-16 BE not yet supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }

    #[tokio::test]
    async fn test_parse_utf16_with_bom() {
        // Tests UTF-16 with Byte Order Mark (Windows standard)
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("utf16_bom.md");

        // Create UTF-16 LE file with BOM
        create_utf16_bom_file(&file_path, UTF16_TEST_CONTENT, true).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        match result {
            Ok(doc) => {
                assert!(doc.content.contains("cafÃ©"));
                assert!(doc.content.contains("ðŸŽ‰"));
                println!("âœ“ UTF-16 with BOM is now supported!");
            }
            Err(e) => {
                eprintln!("âš ï¸  UTF-16 with BOM not yet supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }

    #[tokio::test]
    async fn test_parse_utf16_frontmatter() {
        // Tests UTF-16 file with YAML frontmatter extraction
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("utf16_frontmatter.md");

        // Create UTF-16 LE encoded file
        create_encoded_file(&file_path, UTF16_TEST_CONTENT, encoding_rs::UTF_16LE).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        match result {
            Ok(doc) => {
                // Frontmatter should be parsed correctly
                assert_eq!(
                    doc.metadata
                        .frontmatter
                        .get("title")
                        .and_then(|v| v.as_str()),
                    Some("UTF-16 Test File")
                );
                assert_eq!(
                    doc.metadata
                        .frontmatter
                        .get("encoding")
                        .and_then(|v| v.as_str()),
                    Some("utf-16")
                );
                println!("âœ“ UTF-16 frontmatter parsing is now supported!");
            }
            Err(e) => {
                eprintln!("âš ï¸  UTF-16 frontmatter parsing not yet supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }

    // ===== PRIORITY 2: LEGACY ENCODING TESTS (3 tests) =====

    #[tokio::test]
    async fn test_parse_latin1_encoded_file() {
        // Tests ISO-8859-1 / Latin-1 (legacy files)
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("latin1.md");

        // Create Latin-1 encoded file
        create_encoded_file(&file_path, LEGACY_TEST_CONTENT, encoding_rs::WINDOWS_1252).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        match result {
            Ok(doc) => {
                // Check if special characters are preserved
                assert!(
                    doc.content.contains("cafÃ©") || doc.content.contains("caf"),
                    "Should handle Latin-1 characters"
                );
                println!("âœ“ Latin-1 encoding is now supported!");
            }
            Err(e) => {
                eprintln!("âš ï¸  Latin-1 not yet supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }

    #[tokio::test]
    async fn test_parse_windows1252_encoded_file() {
        // Tests Windows-1252 (Windows legacy encoding)
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("windows1252.md");

        // Create Windows-1252 encoded file
        create_encoded_file(&file_path, LEGACY_TEST_CONTENT, encoding_rs::WINDOWS_1252).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        match result {
            Ok(doc) => {
                assert!(
                    doc.content.contains("cafÃ©") || doc.content.contains("caf"),
                    "Should handle Windows-1252 characters"
                );
                println!("âœ“ Windows-1252 encoding is now supported!");
            }
            Err(e) => {
                eprintln!("âš ï¸  Windows-1252 not yet supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }

    #[tokio::test]
    async fn test_parse_utf8_with_bom() {
        // Tests UTF-8 with BOM (some editors add this)
        // CRITICAL BUG: UTF-8 BOM breaks frontmatter parsing!
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("utf8_bom.md");

        let content = r#"---
title: UTF-8 with BOM
---
# Test Content

UTF-8 content with BOM marker.
"#;

        // Create UTF-8 file with BOM
        create_utf8_bom_file(&file_path, content).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        match result {
            Ok(doc) => {
                // File content should be readable
                assert!(
                    doc.content.contains("Test Content") || doc.content.contains("UTF-8"),
                    "Should read file content despite BOM"
                );

                // KNOWN BUG: UTF-8 BOM breaks frontmatter parsing
                // The BOM (U+FEFF) at the start of the file causes the YAML parser to fail
                // because it sees "---" with a BOM prefix instead of pure "---"
                let title = doc.metadata.frontmatter.get("title").and_then(|v| v.as_str());

                if title.is_some() {
                    // If frontmatter was parsed, BOM handling was added!
                    println!("âœ“ UTF-8 BOM handling is now implemented!");
                    assert!(
                        title.unwrap().contains("UTF-8 with BOM"),
                        "Title should be parsed correctly"
                    );
                } else {
                    // Expected: BOM breaks frontmatter parsing
                    eprintln!("âš ï¸  CONFIRMED BUG: UTF-8 BOM breaks frontmatter parsing");
                    eprintln!("    File is readable but frontmatter is lost");
                    assert!(
                        doc.metadata.frontmatter.is_empty(),
                        "Frontmatter should be empty when BOM breaks parsing (current behavior)"
                    );
                }
            }
            Err(e) => {
                eprintln!("âš ï¸  UTF-8 with BOM handling issue: {:?}", e);
                panic!("UTF-8 with BOM should parse successfully: {:?}", e);
            }
        }
    }

    // ===== PRIORITY 3: MIXED CONTENT TESTS (3 tests) =====

    #[tokio::test]
    async fn test_parse_mixed_encoding_vault() {
        // Tests vault with both UTF-8 and UTF-16 files
        let temp_dir = TempDir::new().unwrap();

        // Create UTF-8 file
        let utf8_file = temp_dir.path().join("utf8_file.md");
        fs::write(&utf8_file, "# UTF-8 File\n\nContent in UTF-8").unwrap();

        // Create UTF-16 file
        let utf16_file = temp_dir.path().join("utf16_file.md");
        create_encoded_file(&utf16_file, "# UTF-16 File\n\nContent in UTF-16", encoding_rs::UTF_16LE)
            .unwrap();

        let parser = crucible_tools::vault_parser::VaultParser::new();

        // UTF-8 should work
        let utf8_result = parser.parse_file(utf8_file.to_str().unwrap()).await;
        assert!(utf8_result.is_ok(), "UTF-8 file should parse successfully");

        // UTF-16 currently fails (expected)
        let utf16_result = parser
            .parse_file(utf16_file.to_str().unwrap())
            .await;
        match utf16_result {
            Ok(_) => {
                println!("âœ“ Mixed encoding vault is now supported!");
            }
            Err(e) => {
                eprintln!("âš ï¸  Mixed encoding not yet fully supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }

    #[tokio::test]
    async fn test_parse_malformed_utf8() {
        // Tests file with invalid UTF-8 sequences
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("malformed.md");

        // Create file with invalid UTF-8
        create_malformed_utf8_file(&file_path).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        // Should fail with UTF-8 error
        assert!(
            result.is_err(),
            "Malformed UTF-8 should produce an error"
        );

        match result {
            Err(e) => {
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention UTF-8 issue, got: {}",
                    e
                );
                eprintln!("âœ“ Malformed UTF-8 correctly rejected: {:?}", e);
            }
            Ok(_) => {
                panic!("Malformed UTF-8 should not parse successfully");
            }
        }
    }

    #[tokio::test]
    async fn test_parse_replacement_characters() {
        // Tests file with UTF-8 replacement character (U+FFFD)
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("replacement.md");

        let content = "# Test File\n\nContent with replacement char: \u{FFFD}";
        fs::write(&file_path, content).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await
            .unwrap();

        // Should parse successfully but preserve replacement char
        assert!(result.content.contains('\u{FFFD}'));
        println!("âœ“ Replacement characters are preserved correctly");
    }

    // ===== PRIORITY 4: SPECIAL CHARACTER TESTS (3 tests) =====

    #[tokio::test]
    async fn test_parse_emoji_in_utf16() {
        // Tests emoji in UTF-16 file
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("emoji_utf16.md");

        let content = r#"---
title: Emoji Test
---
# Emoji Content

Various emoji: ðŸ˜€ ðŸŽ‰ ðŸš€ âœ¨ ðŸ’¡ ðŸ”¥ âš¡ ðŸŒŸ
"#;

        // Create UTF-16 LE encoded file
        create_encoded_file(&file_path, content, encoding_rs::UTF_16LE).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        match result {
            Ok(doc) => {
                assert!(doc.content.contains("ðŸŽ‰"));
                assert!(doc.content.contains("ðŸš€"));
                println!("âœ“ Emoji in UTF-16 is now supported!");
            }
            Err(e) => {
                eprintln!("âš ï¸  Emoji in UTF-16 not yet supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }

    #[tokio::test]
    async fn test_parse_multilingual_content() {
        // Tests Chinese, Arabic, Cyrillic in UTF-16
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("multilingual_utf16.md");

        // Create UTF-16 encoded file
        create_encoded_file(&file_path, MULTILINGUAL_CONTENT, encoding_rs::UTF_16LE).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        match result {
            Ok(doc) => {
                assert!(doc.content.contains("ä½ å¥½ä¸–ç•Œ"));
                assert!(doc.content.contains("Ù…Ø±Ø­Ø¨Ø§"));
                assert!(doc.content.contains("ÐŸÑ€Ð¸Ð²ÐµÑ‚"));
                println!("âœ“ Multilingual content in UTF-16 is now supported!");
            }
            Err(e) => {
                eprintln!("âš ï¸  Multilingual UTF-16 not yet supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }

    #[tokio::test]
    async fn test_parse_special_unicode_ranges() {
        // Tests mathematical symbols, box drawing, etc.
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("special_unicode.md");

        let content = r#"---
title: Special Unicode Test
---
# Special Characters

Mathematical symbols: âˆ€ âˆƒ âˆˆ âˆ‰ âˆ« âˆ‘ âˆ âˆš âˆž â‰ˆ â‰  â‰¤ â‰¥
Box drawing: â”Œâ”€â” â”‚ â”‚ â””â”€â”˜ â•”â•â•— â•‘ â•‘ â•šâ•â•
Arrows: â† â†’ â†‘ â†“ â†” â‡ â‡’ â‡”
"#;

        // Create UTF-16 LE encoded file
        create_encoded_file(&file_path, content, encoding_rs::UTF_16LE).unwrap();

        // Try to parse
        let parser = crucible_tools::vault_parser::VaultParser::new();
        let result = parser
            .parse_file(file_path.to_str().unwrap())
            .await;

        match result {
            Ok(doc) => {
                assert!(doc.content.contains("âˆ€"));
                assert!(doc.content.contains("â”Œ"));
                assert!(doc.content.contains("â†’"));
                println!("âœ“ Special Unicode ranges in UTF-16 are now supported!");
            }
            Err(e) => {
                eprintln!("âš ï¸  Special Unicode in UTF-16 not yet supported: {:?}", e);
                let error_msg = e.to_string().to_lowercase();
                assert!(
                    error_msg.contains("utf") || error_msg.contains("invalid") || error_msg.contains("stream"),
                    "Error should mention encoding issue, got: {}",
                    e
                );
            }
        }
    }
}

// ===== ENCODING TEST SUMMARY =====
//
// Total tests added: 13
//
// Priority 1 - UTF-16 Tests (4):
// - test_parse_utf16_le_encoded_file
// - test_parse_utf16_be_encoded_file
// - test_parse_utf16_with_bom
// - test_parse_utf16_frontmatter
//
// Priority 2 - Legacy Encoding Tests (3):
// - test_parse_latin1_encoded_file
// - test_parse_windows1252_encoded_file
// - test_parse_utf8_with_bom
//
// Priority 3 - Mixed Content Tests (3):
// - test_parse_mixed_encoding_vault
// - test_parse_malformed_utf8
// - test_parse_replacement_characters
//
// Priority 4 - Special Character Tests (3):
// - test_parse_emoji_in_utf16
// - test_parse_multilingual_content
// - test_parse_special_unicode_ranges
//
// EXPECTED RESULTS:
// - UTF-8 baseline: PASS
// - UTF-16 tests: FAIL (documents limitation)
// - Legacy encoding tests: FAIL (documents limitation)
// - Malformed UTF-8: FAIL (expected behavior)
// - Replacement chars: PASS (valid UTF-8)
//
// DOCUMENTED GAPS:
// 1. No UTF-16 support (Windows users will have issues)
// 2. No Latin-1/Windows-1252 support (legacy file issues)
// 3. No BOM handling (some editors add BOM markers)
// 4. No encoding auto-detection
// 5. Silent failures or garbage output for non-UTF-8
//
// FUTURE ENHANCEMENT PATH:
// To add encoding support, implement encoding auto-detection in vault_parser.rs:
//
// ```rust
// use encoding_rs::Encoding;
// use encoding_rs_io::DecodeReaderBytesBuilder;
//
// fn read_file_with_encoding_detection(path: &Path) -> Result<String> {
//     let file = File::open(path)?;
//     let mut decoder = DecodeReaderBytesBuilder::new()
//         .encoding(None)  // Auto-detect
//         .build(file);
//
//     let mut content = String::new();
//     decoder.read_to_string(&mut content)?;
//     Ok(content)
// }
// ```
