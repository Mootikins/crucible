/// K-means clustering plugin for Crucible
///
/// This plugin implements K-means clustering algorithm for organizing documents
/// based on their embeddings, links, tags, and content similarity.
///
/// Usage:
///   Load documents with embeddings
///   Run kmeans_cluster with k value
///   Get optimized clusters with document assignments

// ===== K-MEANS ALGORITHM IMPLEMENTATION =====

/// Calculate Euclidean distance between two vectors
pub fn euclidean_distance(a, b) {
    if a.len() != b.len() {
        panic!("Vectors must have same dimension");
    }

    let mut sum = 0.0;
    for i in 0..a.len() {
        let diff = a[i] - b[i];
        sum += diff * diff;
    }
    sqrt(sum)
}

/// Calculate cosine similarity between two vectors
pub fn cosine_similarity(a, b) {
    if a.len() != b.len() {
        panic!("Vectors must have same dimension");
    }

    let mut dot_product = 0.0;
    let mut norm_a = 0.0;
    let mut norm_b = 0.0;

    for i in 0..a.len() {
        dot_product += a[i] * b[i];
        norm_a += a[i] * a[i];
        norm_b += b[i] * b[i];
    }

    if norm_a == 0.0 || norm_b == 0.0 {
        return 0.0;
    }

    dot_product / (sqrt(norm_a) * sqrt(norm_b))
}

/// Initialize centroids using k-means++ algorithm
pub fn initialize_centroids(data, k) {
    let n = data.len();
    if k > n {
        panic!("K cannot be greater than number of data points");
    }

    let mut centroids = [];
    let mut distances = vec![0.0; n];

    // Choose first centroid randomly
    let first_idx = rand_int(0, n - 1);
    centroids.push(data[first_idx].clone());

    // Choose remaining centroids
    for _ in 1..k {
        // Calculate distances to nearest centroid
        for i in 0..n {
            let mut min_dist = f64::MAX;
            for centroid in centroids {
                let dist = euclidean_distance(data[i], centroid);
                if dist < min_dist {
                    min_dist = dist;
                }
            }
            distances[i] = min_dist * min_dist; // Square for probability
        }

        // Choose next centroid with probability proportional to distance
        let total_dist = distances.sum();
        let mut r = rand_float() * total_dist;

        let mut next_idx = 0;
        for i in 0..n {
            r -= distances[i];
            if r <= 0.0 {
                next_idx = i;
                break;
            }
        }

        centroids.push(data[next_idx].clone());
    }

    centroids
}

/// Assign each data point to nearest centroid
pub fn assign_clusters(data, centroids) {
    let mut assignments = vec![0; data.len()];

    for i in 0..data.len() {
        let mut min_dist = f64::MAX;
        let mut closest_centroid = 0;

        for j in 0..centroids.len() {
            let dist = euclidean_distance(data[i], centroids[j]);
            if dist < min_dist {
                min_dist = dist;
                closest_centroid = j;
            }
        }

        assignments[i] = closest_centroid;
    }

    assignments
}

/// Update centroids based on assigned points
pub fn update_centroids(data, assignments, k, dimension) {
    let mut centroids = vec![vec![0.0; dimension]; k];
    let mut counts = vec![0; k];

    // Sum points for each cluster
    for i in 0..data.len() {
        let cluster = assignments[i];
        for j in 0..dimension {
            centroids[cluster][j] += data[i][j];
        }
        counts[cluster] += 1;
    }

    // Calculate averages
    for j in 0..k {
        if counts[j] > 0 {
            for d in 0..dimension {
                centroids[j][d] /= counts[j] as f64;
            }
        }
    }

    centroids
}

/// Check if centroids have converged
pub fn check_convergence(old_centroids, new_centroids, tolerance) {
    for i in 0..old_centroids.len() {
        if euclidean_distance(old_centroids[i], new_centroids[i]) > tolerance {
            return false;
        }
    }
    true
}

/// Main K-means clustering function
pub fn kmeans_cluster(data, k, max_iterations, tolerance) {
    if data.is_empty() {
        panic!("Data cannot be empty");
    }

    let dimension = data[0].len();
    let mut centroids = initialize_centroids(data, k);
    let mut assignments = vec![0; data.len()];

    for iteration in 0..max_iterations {
        // Assign points to clusters
        let new_assignments = assign_clusters(data, centroids);

        // Check for convergence
        if new_assignments == assignments {
            break;
        }

        assignments = new_assignments;

        // Update centroids
        let new_centroids = update_centroids(data, assignments, k, dimension);

        // Check for convergence
        if check_convergence(centroids, new_centroids, tolerance) {
            break;
        }

        centroids = new_centroids;
    }

    // Organize results into clusters
    let mut clusters = vec![[]; k];
    for i in 0..data.len() {
        clusters[assignments[i]].push(i);
    }

    {
        "centroids": centroids,
        "assignments": assignments,
        "clusters": clusters,
        "iterations": iteration,
        "converged": converged
    }
}

// ===== DOCUMENT FEATURE EXTRACTION =====

/// Convert documents to feature vectors
/// Combines embeddings, link patterns, tag similarity, and content features
pub fn documents_to_features(documents) {
    let mut features = [];
    let dimension = 384; // Default embedding dimension
    let link_weight = 0.3;
    let tag_weight = 0.2;
    let content_weight = 0.5;

    for doc in documents {
        let mut vector = vec![0.0; dimension];

        // Add embedding features (if available)
        if doc.has("embedding") {
            let embedding = doc["embedding"];
            for i in 0..dimension.min(embedding.len()) {
                vector[i] += embedding[i] * content_weight;
            }
        }

        // Add link-based features
        if doc.has("links") && doc.has("inbound_links") {
            let total_links = doc["links"].len() + doc["inbound_links"].len();
            let link_score = if total_links > 0 {
                log2(total_links as f64 + 1.0) / 10.0 // Normalize
            } else {
                0.0
            };

            // Add link score to first few dimensions
            for i in 0..10.min(dimension) {
                vector[i] += link_score * link_weight;
            }
        }

        // Add tag features
        if doc.has("tags") && !doc["tags"].is_empty() {
            let tag_hash = hash_tags(doc["tags"]);
            // Distribute tag features across dimensions
            for i in 0..dimension {
                vector[i] += ((tag_hash as f64 + i as f64) % 1.0 - 0.5) * tag_weight;
            }
        }

        // Add content length feature
        if doc.has("content_length") {
            let length_score = log2(doc["content_length"] as f64 + 1.0) / 20.0;
            for i in 0..5.min(dimension) {
                vector[i] += length_score * content_weight * 0.1;
            }
        }

        features.push(vector);
    }

    features
}

/// Hash tags to create distributed feature representation
pub fn hash_tags(tags) {
    if tags.is_empty() {
        return 0;
    }

    let mut hash = 0;
    for tag in tags {
        // Simple string hash
        for c in tag.chars() {
            hash = hash * 31 + (c as i32);
        }
    }
    hash.abs()
}

// ===== CLUSTER EVALUATION =====

/// Calculate silhouette score for clustering quality
pub fn silhouette_score(data, assignments) {
    let n = data.len();
    let mut total_score = 0.0;

    for i in 0..n {
        let cluster_i = assignments[i];

        // Calculate a(i): average distance to points in same cluster
        let mut a_i = 0.0;
        let mut same_cluster_count = 0;

        for j in 0..n {
            if assignments[j] == cluster_i && i != j {
                a_i += euclidean_distance(data[i], data[j]);
                same_cluster_count += 1;
            }
        }

        if same_cluster_count > 0 {
            a_i /= same_cluster_count as f64;
        } else {
            a_i = 0.0;
        }

        // Calculate b(i): minimum average distance to points in other clusters
        let mut b_i = f64::MAX;
        let mut clusters = {};

        for j in 0..n {
            clusters[assignments[j]] = true;
        }

        for cluster in clusters.keys() {
            if cluster != cluster_i {
                let mut avg_dist = 0.0;
                let mut count = 0;

                for j in 0..n {
                    if assignments[j] == cluster {
                        avg_dist += euclidean_distance(data[i], data[j]);
                        count += 1;
                    }
                }

                if count > 0 {
                    avg_dist /= count as f64;
                    if avg_dist < b_i {
                        b_i = avg_dist;
                    }
                }
            }
        }

        // Calculate silhouette for point i
        let s_i = if b_i == f64::MAX {
            0.0
        } else if same_cluster_count == 0 {
            0.0
        } else {
            (b_i - a_i) / max(a_i, b_i)
        };

        total_score += s_i;
    }

    total_score / n as f64
}

/// Optimize number of clusters using elbow method
pub fn optimize_k(data, max_k) {
    let mut scores = [];
    let mut previous_score = 0.0;

    for k in 2..=max_k {
        let result = kmeans_cluster(data, k, 100, 0.001);
        let s_score = silhouette_score(data, result["assignments"]);

        // Calculate elbow improvement
        let improvement = if k == 2 {
            s_score
        } else {
            s_score - previous_score
        };

        scores.push({
            "k": k,
            "silhouette": s_score,
            "improvement": improvement
        });

        previous_score = s_score;
    }

    // Find elbow point (largest drop in improvement)
    let mut best_k = 2;
    let mut max_drop = 0.0;

    for i in 1..scores.len() {
        let drop = scores[i - 1]["improvement"] - scores[i]["improvement"];
        if drop > max_drop {
            max_drop = drop;
            best_k = scores[i]["k"];
        }
    }

    {
        "best_k": best_k,
        "scores": scores,
        "clusters": kmeans_cluster(data, best_k, 100, 0.001)
    }
}

// ===== MAIN PLUGIN ENTRY POINT =====

/// Main function exposed to the clustering system
/// Takes documents and returns optimized clusters
pub fn cluster_documents(documents, suggested_k) {
    // Convert documents to feature vectors
    let features = documents_to_features(documents);

    if features.is_empty() {
        return {
            "error": "No documents to cluster",
            "clusters": []
        };
    }

    // Determine optimal K if not provided
    let k = if suggested_k && suggested_k > 1 {
        suggested_k.min(features.len())
    } else {
        // Auto-detect using elbow method
        let max_k = min(10, features.len() / 2);
        let optimization = optimize_k(features, max_k);
        optimization["best_k"]
    };

    // Run K-means clustering
    let result = kmeans_cluster(features, k, 100, 0.001);

    // Calculate quality metrics
    let quality = silhouette_score(features, result["assignments"]);

    // Format output with document IDs
    let mut output_clusters = [];
    for cluster_docs in result["clusters"] {
        let mut cluster = [];
        for doc_idx in cluster_docs {
            cluster.push({
                "id": doc_idx,
                "title": documents[doc_idx]["title"],
                "path": documents[doc_idx]["path"]
            });
        }
        output_clusters.push({
            "documents": cluster,
            "size": cluster.len()
        });
    }

    {
        "algorithm": "kmeans",
        "k": k,
        "quality": quality,
        "iterations": result["iterations"],
        "converged": result["converged"],
        "clusters": output_clusters,
        "total_documents": documents.len()
    }
}

// Example usage:
// let documents = [
//   {
//     "id": 1,
//     "title": "Machine Learning Basics",
//     "path": "/ml/basics.md",
//     "embedding": [0.1, 0.2, 0.3, ...],
//     "tags": ["ml", "basics"],
//     "links": ["neural-networks.md"],
//     "inbound_links": [],
//     "content_length": 2500
//   },
//   ...
// ];
//
// let result = cluster_documents(documents, 5);
// println("Found {} clusters with quality score: {}", result["k"], result["quality"]);